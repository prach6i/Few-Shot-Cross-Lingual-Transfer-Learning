{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import copy \n",
    "import time\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. mBERT or XLM-R ?    \n",
    "Ans. XLM-R because it is more recent.\n",
    "\n",
    "Q2. Fine-tuning or Use of Adapters? If fine-tuning then translate-train or translate-test?   \n",
    "Ans. Let's start with fine-tuning as parameter efficiency is not essential for us.\n",
    "\n",
    "Q3. Which languages (out of the total 14) to use? Can we remove langues which are totally unrelated to the test languages (Chinese, Hindi, Swahili and Spanish)?\n",
    "\n",
    "Q4. Should we create 4 models (one for each of the 4 languages) or 1 model (for all 4 languages)?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Experiments: \n",
    "1. - Start with a single **XLM-R** model and use all the **14** provided languages to **fine-tune** it.\n",
    "   - Identify and **remove noisy languages** (from the 14 languages) then **fine-tune**. \n",
    "2. Create 4 separate language models for each of the 4 test languages. \n",
    "   - Each model uses all the training languages for fine-tuning. \n",
    "   - Each model uses only the languages which are closer to the corresponding model's test language. \n",
    "3. Use of Adapters ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-tuning strategies:**\n",
    "- Translate-train: \n",
    "    - translate all data to target language 'x' and fine-tune the model corresponding to 'x' on the translated data \n",
    "    - might lead to noisy data due to poor translations\n",
    "- Translate-test: \n",
    "    - PROS:\n",
    "        - train on original English data only\n",
    "        - at inference, translate the target language sentence to English\n",
    "        - maybe a better approach as the number of translation to be made is less and, generally, \\\n",
    "          translations into english are more accurate than translations from english to a different language. \n",
    "    - CONS:\n",
    "        - Unutilized training data of other languages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114993, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>At ground level, the asymmetrical cathedral is...</td>\n",
       "      <td>It's hard to find a dramatic view of the cathe...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>Hanuman is a beneficent deity predating classi...</td>\n",
       "      <td>Hanuman declared that all the lemurs here need...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>All other spending as well as federal revenue ...</td>\n",
       "      <td>None of the federal spending is assumed to grow</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>uh-huh that's interesting well it sounds as th...</td>\n",
       "      <td>That information about graduation rates is int...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Some kind of instant recognition on his father...</td>\n",
       "      <td>Did his father recognize him?</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                            premise  \\\n",
       "0        neutral  At ground level, the asymmetrical cathedral is...   \n",
       "1  contradiction  Hanuman is a beneficent deity predating classi...   \n",
       "2  contradiction  All other spending as well as federal revenue ...   \n",
       "3        neutral  uh-huh that's interesting well it sounds as th...   \n",
       "4        neutral  Some kind of instant recognition on his father...   \n",
       "\n",
       "                                          hypothesis language  \n",
       "0  It's hard to find a dramatic view of the cathe...       en  \n",
       "1  Hanuman declared that all the lemurs here need...       en  \n",
       "2    None of the federal spending is assumed to grow       en  \n",
       "3  That information about graduation rates is int...       en  \n",
       "4                      Did his father recognize him?       en  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv(\"/home/ddsb01/Desktop/NLP/Assign/A3/data/train/train.tsv\", sep='\\t')\n",
    "data = pd.read_csv(\"data/train/train.tsv\", sep='\\t')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112993, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>At ground level, the asymmetrical cathedral is...</td>\n",
       "      <td>It's hard to find a dramatic view of the cathe...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>Hanuman is a beneficent deity predating classi...</td>\n",
       "      <td>Hanuman declared that all the lemurs here need...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>All other spending as well as federal revenue ...</td>\n",
       "      <td>None of the federal spending is assumed to grow</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>uh-huh that's interesting well it sounds as th...</td>\n",
       "      <td>That information about graduation rates is int...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Some kind of instant recognition on his father...</td>\n",
       "      <td>Did his father recognize him?</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                            premise  \\\n",
       "0        neutral  At ground level, the asymmetrical cathedral is...   \n",
       "1  contradiction  Hanuman is a beneficent deity predating classi...   \n",
       "2  contradiction  All other spending as well as federal revenue ...   \n",
       "3        neutral  uh-huh that's interesting well it sounds as th...   \n",
       "4        neutral  Some kind of instant recognition on his father...   \n",
       "\n",
       "                                          hypothesis language  \n",
       "0  It's hard to find a dramatic view of the cathe...       en  \n",
       "1  Hanuman declared that all the lemurs here need...       en  \n",
       "2    None of the federal spending is assumed to grow       en  \n",
       "3  That information about graduation rates is int...       en  \n",
       "4                      Did his father recognize him?       en  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gold_label', 'premise', 'hypothesis', 'language'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = data.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100993, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>At ground level, the asymmetrical cathedral is...</td>\n",
       "      <td>It's hard to find a dramatic view of the cathe...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>Hanuman is a beneficent deity predating classi...</td>\n",
       "      <td>Hanuman declared that all the lemurs here need...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>All other spending as well as federal revenue ...</td>\n",
       "      <td>None of the federal spending is assumed to grow</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>uh-huh that's interesting well it sounds as th...</td>\n",
       "      <td>That information about graduation rates is int...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Some kind of instant recognition on his father...</td>\n",
       "      <td>Did his father recognize him?</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                            premise  \\\n",
       "0        neutral  At ground level, the asymmetrical cathedral is...   \n",
       "1  contradiction  Hanuman is a beneficent deity predating classi...   \n",
       "2  contradiction  All other spending as well as federal revenue ...   \n",
       "3        neutral  uh-huh that's interesting well it sounds as th...   \n",
       "4        neutral  Some kind of instant recognition on his father...   \n",
       "\n",
       "                                          hypothesis language  \n",
       "0  It's hard to find a dramatic view of the cathe...       en  \n",
       "1  Hanuman declared that all the lemurs here need...       en  \n",
       "2    None of the federal spending is assumed to grow       en  \n",
       "3  That information about graduation rates is int...       en  \n",
       "4                      Did his father recognize him?       en  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_data = data[data['language']=='en']\n",
    "print(eng_data.shape)\n",
    "eng_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gold_label, premise, hypothesis, language]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_data = data[data['language']=='ur']\n",
    "print(eng_data.shape)\n",
    "eng_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_langs = ['hi', 'sw', 'zh', 'es']\n",
    "target_languages = ['Hindi', 'Swahili', 'Chinese', 'Spanish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bg' 'de' 'el' 'en' 'es' 'fr' 'hi' 'ru' 'sw' 'th' 'tr' 'vi' 'zh']\n",
      "{'bg': 1000, 'de': 1000, 'el': 1000, 'en': 100993, 'es': 1000, 'fr': 1000, 'hi': 1000, 'ru': 1000, 'sw': 1000, 'th': 1000, 'tr': 1000, 'vi': 1000, 'zh': 1000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 13 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# different languages present in the data:\n",
    "langs = np.unique(data['language'])\n",
    "print(langs)\n",
    "\n",
    "lang_dict = {} \n",
    "for lang in langs:\n",
    "    lang_dict[lang] = data[data['language']==lang].shape[0]\n",
    "print(lang_dict)\n",
    "plt.bar(lang_dict.keys(), height=lang_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contradiction' 'entailment' 'neutral']\n",
      "{'contradiction': 39465, 'entailment': 38113, 'neutral': 35415}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = np.unique(data['gold_label'])\n",
    "print(labels)\n",
    "\n",
    "label_dict = {}\n",
    "for label in labels:\n",
    "    label_dict[label] = data[data['gold_label']==label].shape[0]\n",
    "print(label_dict)\n",
    "plt.bar(label_dict.keys(), height=label_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping a copy of the originial data:\n",
    "orig_data = copy.deepcopy(data)\n",
    "train_data = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37350, 19) (75150, 19)\n"
     ]
    }
   ],
   "source": [
    "# xnli_dev = pd.read_csv(\"/home/ddsb01/Desktop/NLP/Assign/A3/data/xnli/xnli.dev.tsv\", sep='\\t') \n",
    "# xnli_test = pd.read_csv(\"/home/ddsb01/Desktop/NLP/Assign/A3/data/xnli/xnli.test.tsv\", sep='\\t')\n",
    "xnli_dev = pd.read_csv(\"data/xnli/xnli.dev.tsv\", sep='\\t') \n",
    "xnli_test = pd.read_csv(\"data/xnli/xnli.test.tsv\", sep='\\t')\n",
    "print(xnli_dev.shape, xnli_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['language', 'gold_label', 'sentence1_binary_parse',\n",
       "       'sentence2_binary_parse', 'sentence1_parse', 'sentence2_parse',\n",
       "       'sentence1', 'sentence2', 'promptID', 'pairID', 'genre', 'label1',\n",
       "       'label2', 'label3', 'label4', 'label5', 'sentence1_tokenized',\n",
       "       'sentence2_tokenized', 'match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnli_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['facetoface' 'fiction' 'government' 'letters' 'nineeleven' 'oup' 'slate'\n",
      " 'telephone' 'travel' 'verbatim']\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "genres = np.unique(xnli_test['genre']) \n",
    "print(genres) \n",
    "print(genres.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9960, 5)\n"
     ]
    }
   ],
   "source": [
    "req_cols = ['gold_label', 'sentence1', 'sentence2', 'language', 'genre'] \n",
    "# required: ['gold_label', 'premise', 'hypothesis', 'language']\n",
    "# taking 'genre' as well for possible finer fine-tuning (since we know the test genres)\n",
    "\n",
    "val_data_from_dev = xnli_dev[(xnli_dev['language']=='hi') | (xnli_dev['language']=='zh') | (xnli_dev['language']=='sw') | (xnli_dev['language']=='es')][req_cols] # 2.5k per language (the 1k given to us belong here i.e., it contains the target languages' training data itself!)\n",
    "# val_data_from_test = xnli_test[(xnli_test['language']=='hi') | (xnli_test['language']=='zh') | (xnli_test['language']=='sw') | (xnli_test['language']=='es')][req_cols] # 5k per language\n",
    "# dfs = [val_data_from_dev, val_data_from_test]\n",
    "# val_data = pd.concat(dfs)\n",
    "val_data=val_data_from_dev\n",
    "print(val_data.shape)\n",
    "\n",
    "# rename the columns to match 'data'\n",
    "val_data.rename(columns={'sentence1':'premise', 'sentence2':'hypothesis'}, inplace=True)\n",
    "# val_data.to_csv('/home/ddsb01/Desktop/NLP/Assign/A3/data/train/val.tsv', sep='\\t', index=False)\n",
    "val_data = pd.read_csv(\"data/train/val.tsv\", sep='\\t')\n",
    "# val_data.to_csv('train/val1.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9960, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Y l dijo: Mam, estoy en casa.</td>\n",
       "      <td>Llam a su madre tan pronto como el autobs es...</td>\n",
       "      <td>es</td>\n",
       "      <td>facetoface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>Y l dijo: Mam, estoy en casa.</td>\n",
       "      <td>l no dijo una palabra.</td>\n",
       "      <td>es</td>\n",
       "      <td>facetoface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entailment</td>\n",
       "      <td>Y l dijo: Mam, estoy en casa.</td>\n",
       "      <td>Le dijo a su madre que haba llegado a casa.</td>\n",
       "      <td>es</td>\n",
       "      <td>facetoface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>No saba para qu iba ni nada, as que iba a i...</td>\n",
       "      <td>Nunca he estado en Washington, as que cuando ...</td>\n",
       "      <td>es</td>\n",
       "      <td>facetoface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>No saba para qu iba ni nada, as que iba a i...</td>\n",
       "      <td>Saba exactamente lo que tena que hacer mient...</td>\n",
       "      <td>es</td>\n",
       "      <td>facetoface</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                            premise  \\\n",
       "0        neutral                    Y l dijo: Mam, estoy en casa.   \n",
       "1  contradiction                    Y l dijo: Mam, estoy en casa.   \n",
       "2     entailment                    Y l dijo: Mam, estoy en casa.   \n",
       "3        neutral  No saba para qu iba ni nada, as que iba a i...   \n",
       "4  contradiction  No saba para qu iba ni nada, as que iba a i...   \n",
       "\n",
       "                                          hypothesis language       genre  \n",
       "0  Llam a su madre tan pronto como el autobs es...       es  facetoface  \n",
       "1                            l no dijo una palabra.       es  facetoface  \n",
       "2       Le dijo a su madre que haba llegado a casa.       es  facetoface  \n",
       "3  Nunca he estado en Washington, as que cuando ...       es  facetoface  \n",
       "4  Saba exactamente lo que tena que hacer mient...       es  facetoface  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val_data = pd.read_csv(\"/home/ddsb01/Desktop/NLP/Assign/A3/data/train/val.tsv\", sep='\\t') \n",
    "val_data = pd.read_csv(\"data/train/val.tsv\", sep='\\t') \n",
    "# val_data = pd.read_csv(\"train/val1.tsv\", sep='\\t')\n",
    "print(val_data.shape)\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4980, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the val_data to include only the probable test genres (5 out of the total 10 genres)\n",
    "genre_val_data = val_data[\n",
    "                            (val_data['genre']=='facetoface') | \n",
    "                            (val_data['genre']=='fiction') |\n",
    "                            (val_data['genre']=='oup') |\n",
    "                            (val_data['genre']=='telephone') |\n",
    "                            (val_data['genre']=='travel') \n",
    "                         ]\n",
    "genre_val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>           ...</td>\n",
       "      <td>    .</td>\n",
       "      <td>ar</td>\n",
       "      <td>facetoface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>           ...</td>\n",
       "      <td>         ...</td>\n",
       "      <td>ar</td>\n",
       "      <td>facetoface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>           ...</td>\n",
       "      <td>   .</td>\n",
       "      <td>ar</td>\n",
       "      <td>facetoface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>           ...</td>\n",
       "      <td>          ...</td>\n",
       "      <td>ar</td>\n",
       "      <td>facetoface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entailment</td>\n",
       "      <td>           ...</td>\n",
       "      <td>        ...</td>\n",
       "      <td>ar</td>\n",
       "      <td>facetoface</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                            premise  \\\n",
       "0  contradiction             ...   \n",
       "1     entailment             ...   \n",
       "2        neutral             ...   \n",
       "3        neutral             ...   \n",
       "4     entailment             ...   \n",
       "\n",
       "                                          hypothesis language       genre  \n",
       "0                                 .       ar  facetoface  \n",
       "1           ...       ar  facetoface  \n",
       "2                                  .       ar  facetoface  \n",
       "3            ...       ar  facetoface  \n",
       "4          ...       ar  facetoface  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking all of xnli_test for validation\n",
    "all_val_data = xnli_test[req_cols]\n",
    "all_val_data.rename(columns={'sentence1':'premise', 'sentence2':'hypothesis'}, inplace=True) \n",
    "print(all_val_data.shape)\n",
    "all_val_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training/Fine-tuning on languages **unrelated** to the target languages might just be noise. Will removing unrelated languages help?           \n",
    "\n",
    "What is an unrelated language? One way is to differentiate as left-to-right vs right-to-left. Another way is phylogenetic trees.        \n",
    "\n",
    "We could also explore fine-tuning on some other task which might help in this NLI task? However, the restriction would be that we have to somehow use the given data only\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been given data from xnli_dev corresponding to 5 genres: {'facetoface', 'fiction', 'telephone', 'oup', 'travel'}   \n",
    "However, we will all the samples (i.e., samples corresponding to all the genres) of the target languages from xnli_test for validaition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Multi-lingual Language Models*\n",
    "\n",
    "- XLMR\n",
    "    - xlm-roberta-base (Masked language modeling, 100 languages) [Use this first]\n",
    "    - xlm-roberta-large (Masked language modeling, 100 languages)\n",
    "\n",
    "- BERT (or mBERT)  \n",
    "    - bert-base-multilingual-uncased (Masked language modeling + Next sentence prediction, 102 languages)\n",
    "    - bert-base-multilingual-cased (Masked language modeling + Next sentence prediction, 104 languages) [New and better] \n",
    "\n",
    "\n",
    "*Translation Models* \n",
    "- m2m100\n",
    "    - facebook/m2m100_418M (Translation)\n",
    "    - facebook/m2m100_1.2B (Translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-apply-bert-to-arabic-and-other-languages-5c3410ddd787"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Why are we using XLM-R (which is multilingual) instead of single BERT (or other) models for each language? \n",
    "Ans. Because of lack of data or because of existence of many *low-resource* language. mBERT is another option but XLM-R has been found to perform better. \n",
    "\n",
    "Q. Do we need to translate-train when working with XLM-R?\n",
    "Ans. NO! XLM-R has a shared vocabulary of 250K tokens corresponding to 100 languages which cover all the languages that we are using so there is no need to do any translations into english (or any other language) at test time. Also, no need to add any special markers to indicate the language at the time of fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[K     || 5.5 MB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
      "\u001b[K     || 451 kB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     || 7.6 MB 36.1 MB/s eta 0:00:01     | | 7.3 MB 36.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "\u001b[K     || 182 kB 50.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-10.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
      "\u001b[K     || 35.9 MB 64.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.2)\n",
      "Collecting dill<0.3.7\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[K     || 110 kB 46.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Using cached xxhash-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "Requirement already satisfied: aiohttp in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/prachimsr/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: dill, xxhash, tokenizers, responses, pyarrow, multiprocess, huggingface-hub, transformers, datasets\n",
      "Successfully installed datasets-2.7.1 dill-0.3.6 huggingface-hub-0.11.0 multiprocess-0.70.14 pyarrow-10.0.1 responses-0.18.0 tokenizers-0.13.2 transformers-4.24.0 xxhash-3.1.0\n"
     ]
    }
   ],
   "source": [
    "#  !pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 14:21:30.153151: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 14:21:30.299896: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-26 14:21:30.329864: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-26 14:21:30.821302: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 14:21:30.821363: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 14:21:30.821369: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from torch import nn\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "logging.set_verbosity_warning()\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "# from transformers import AutoModelForMaskedLM, XLMRobertaForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:    \n",
    "- https://github.com/elsheikh21/cross-natural-language-inference/blob/master/XNLI_XLMR.ipynb \n",
    "- https://huggingface.co/salesken/xlm-roberta-base-finetuned-mnli-cross-lingual-transfer\n",
    "- https://github.com/SumitM0432/XLM-RoBERTa-for-Textual-Entailment/tree/e551343fc7b2712744ad6b5ca51abbf824ef417c\n",
    "- https://github.com/PrayushiFaldu/COL772/blob/master/Assignment_3/2021CSY7548_A3_B_train.ipynb   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters ...\n",
    "\n",
    "# global meta\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "VAL_SIZE = 0.3 # => 30% validation data\n",
    "DROP_PROB = 0.1 # dropout probability; higher drop_prob => poor results\n",
    "LR = 5e-6 # higher learning rate => poor results\n",
    "EXT_VAL_DATA = True\n",
    "REMOVE_UNREALTED_LANGS = False\n",
    "ONLY_TRAIN_TARGETS_AND_ENG = False # Target langugages alongwith \"English\"\n",
    "ONLY_TRAIN_TARGETS = False \n",
    "\n",
    "MODEL_NAME = 'xlm-roberta-large' # 'xlm-roberta-base' 'xlm-roberta-large'\n",
    "\n",
    "TRANSLATE_INPUT_TRAIN = False \n",
    "TRANSLATE_INPUT_TEST = False\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "print(torch.cuda.current_device())\n",
    "RANDOM_SEED = 7\n",
    "\n",
    "# Language strings will be used at inference: \n",
    "## might not be used at all since XLM-R identifies languages on it's own w/o need of any language indicators\n",
    "LABEL2STR = {'ar': 'Arabic', 'bg': 'Bulgarian', 'de': 'German', 'el': 'Greek', 'en':'English', 'es': 'Spanish', \n",
    "             'fr': 'French', 'hi': 'Hindi', 'ru': 'Russian' ,'sw': 'Swahili', 'th': 'Thai', 'tr': 'Turkish', \n",
    "             'ur': 'Urdu', 'vi': 'Vietnamese', 'zh': 'Chinese'}\n",
    "STR2LABEL = {v:k for k, v in LABEL2STR.items()}\n",
    "\n",
    "label2idx = {'entailment':0, 'neutral':1, 'contradiction':2} \n",
    "idx2label = {v:k for k, v in label2idx.items()}\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) \n",
    "# xlmr_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)\n",
    "xlmr_tokenizer.do_lower_case = False # setting explicitly because sometimes the above line doesn't work  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REMOVE_UNREALTED_LANGS:\n",
    "    # Not taking two languages: \"Arabic\" and \"Urdu\" while training. \n",
    "    # The four target languages are written left-to-right while these two are written right-to-left\n",
    "    # Removing these languages helps in improving the accuracy over the target languages, \n",
    "    # probably bcz these languages are unrelated to the target languages to a large extent and therefore add noise while training \n",
    "    data = data[\n",
    "            (data['language']=='hi') | \n",
    "            (data['language']=='zh') | \n",
    "            (data['language']=='sw') | \n",
    "            (data['language']=='es') | \n",
    "            (data['language']=='bg') | \n",
    "            (data['language']=='de') | \n",
    "            (data['language']=='el') | \n",
    "            (data['language']=='en') | \n",
    "            (data['language']=='fr') | \n",
    "            (data['language']=='ru') | \n",
    "            (data['language']=='th') | \n",
    "            (data['language']=='tr') | \n",
    "            (data['language']=='vi') \n",
    "            ]\n",
    "\n",
    "if ONLY_TRAIN_TARGETS_AND_ENG:\n",
    "    data = data[\n",
    "            (data['language']=='en') | \n",
    "            (data['language']=='hi') | \n",
    "            (data['language']=='zh') | \n",
    "            (data['language']=='sw') | \n",
    "            (data['language']=='es') \n",
    "            ]\n",
    "\n",
    "if ONLY_TRAIN_TARGETS:\n",
    "    data = data[\n",
    "            (data['language']=='hi') | \n",
    "            (data['language']=='zh') | \n",
    "            (data['language']=='sw') | \n",
    "            (data['language']=='es') \n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "def translate_data(all_data):\n",
    "    pass\n",
    "\n",
    "def preprocess_data(all_data):\n",
    "    '''\n",
    "    # We don't need to translate any sample in all_data bcz all of the samples are from languages on which XLM-R is trained.\n",
    "    # Not required bcz languages can be fed into XLMR w/o translation\n",
    "    if TRANSLATE_INPUT_TRAIN:\n",
    "        # make use of all the input data by converting all the other languages to english\n",
    "        all_data = translate_data(all_data)\n",
    "    else:\n",
    "        # only train on 'English' data samples only\n",
    "        all_data = all_data[all_data['language']=='en']\n",
    "    '''\n",
    "    proposition = all_data[['premise', 'hypothesis']].values.tolist()\n",
    "    all_data['proposition'] = proposition\n",
    "    # print(all_data.shape)\n",
    "    all_data = all_data.dropna() # https://stackoverflow.com/questions/63517293/valueerror-textencodeinput-must-be-uniontextinputsequence-tupleinputsequence\n",
    "    # print(all_data.shape)\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def split_data(all_data):\n",
    "    # for validation take only 30% of the target languages' {Hindi, Chinese, Swahili, Spanish} data\n",
    "    target_langs_data = all_data[(all_data['language']=='hi') | (all_data['language']=='zh') | (all_data['language']=='sw') | (all_data['language']=='es')]\n",
    "    target_train, X_test, y_target_train, y_test = train_test_split(\n",
    "                                                                    target_langs_data, \n",
    "                                                                    target_langs_data.gold_label,\n",
    "                                                                    test_size=VAL_SIZE,\n",
    "                                                                    random_state=RANDOM_SEED,\n",
    "                                                                    stratify=target_langs_data.gold_label.map(label2idx).values\n",
    "                                                                    )\n",
    "    other_langs_data = all_data[~((all_data['language']=='hi') | (all_data['language']=='zh') | (all_data['language']=='sw') | (all_data['language']=='es'))]\n",
    "\n",
    "    dfs = [other_langs_data, target_train]\n",
    "    X_train = pd.concat(dfs)\n",
    "    y_train = X_train['gold_label']\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "def _split_data(all_data):\n",
    "    # for validation take only 30% of the target languages' {Hindi, Chinese, Swahili, Spanish} data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                        # all_data['proposition'],\n",
    "                                                        all_data,\n",
    "                                                        all_data.gold_label, \n",
    "                                                        # all_data.gold_label.map(label2idx).values,\n",
    "                                                        test_size=VAL_SIZE, \n",
    "                                                        random_state=RANDOM_SEED, \n",
    "                                                        stratify=all_data.gold_label.map(label2idx).values\n",
    "                                                        )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "def encode_data(X, y, tokenizer):\n",
    "    '''\n",
    "    X : Propositions\n",
    "    y : labels <=> X_['gold_label'] if all_data instead of all_data['proposition'] in split_data\n",
    "    \n",
    "    text=premise, text_pair=hypothesis, ... makes more sense than text=proposition\n",
    "    bcz in the former case, the segment tokens for text and text_pair are different\n",
    "    '''\n",
    "    encoded_data = []\n",
    "    for _premise, _hypothesis, _label in tqdm(zip(X['premise'], X['hypothesis'], X['gold_label']), total=X.shape[0]):\n",
    "        encoded_dict = tokenizer(\n",
    "                                 text=_premise,\n",
    "                                 text_pair=_hypothesis, \n",
    "                                 # target=?, # what is its use?\n",
    "                                 add_special_tokens=True,\n",
    "                                 return_token_type_ids=True, # token_type_ids like [CLS],[SEP],etc.\n",
    "                                 return_attention_mask=True,\n",
    "                                 max_length=MAX_LEN,\n",
    "                                 padding='max_length',\n",
    "                                 truncation=True,\n",
    "                                 return_tensors='pt' #'pt'=>torch.Tensor object\n",
    "                                )\n",
    "        encoded_data.append({\n",
    "                             # 'premise': _premise, '_hypothesis': _hypothesis,\n",
    "                             'tokenized_text': torch.squeeze(encoded_dict[\"input_ids\"]), # <=> # 'tokenized_text': encoded_dict[\"input_ids\"].flatten(),\n",
    "                             'attention_mask': torch.squeeze(encoded_dict[\"attention_mask\"]), \n",
    "                             'token_types': torch.squeeze(encoded_dict[\"token_type_ids\"]),\n",
    "                             'outputs': torch.LongTensor([label2idx.get(_label)]) # casting to LongTensor is important (for the loss_fn later on; either cast here itself or in the training loop) \n",
    "                            })\n",
    "    '''\n",
    "    for _proposition, _label in tqdm(zip(X, y), total=X.shape[0]):\n",
    "        encoded_dict = tokenizer(\n",
    "                                    text=proposition,\n",
    "                                    add_special_tokens=True,\n",
    "                                    return_token_type_ids=True, # token_type_ids like [CLS],[SEP],etc.\n",
    "                                    padding = 'max_length',\n",
    "                                    truncation=True,\n",
    "                                    max_length=MAX_LEN,\n",
    "                                    return_tensors='pt' #'pt'=>torch.Tensor object\n",
    "                                )\n",
    "        encoded_data.append({\n",
    "                             'propositions': prop, \n",
    "                             'tokenized_text': torch.squeeze(encoded_dict[\"input_ids\"]), # <=> # 'tokenized_text': encoded_dict[\"input_ids\"].flatten(),\n",
    "                             'attention_mask': torch.squeeze(encoded_dict[\"attention_mask\"]), \n",
    "                             'token_types': torch.squeeze(encoded_dict[\"token_type_ids\"]),\n",
    "                             'outputs': torch.LongTensor([label2idx.get(_label)])\n",
    "                            })\n",
    "    '''\n",
    "    return encoded_data\n",
    "\n",
    "\n",
    "def create_dataloader(encoded_data):\n",
    "    return DataLoader(encoded_data, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention masks are boolean arrays which tell which token should be attended to, and which should not.\n",
    "The attention mask is a binary tensor indicating the position of the padded indices so that the model does not attend to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Translate-train-all setting where the data of all the languages (which have been achieved via translation) is also used on top of the source language (usually English) for training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 112993/112993 [00:35<00:00, 3177.69it/s]\n",
      "100%|| 9960/9960 [00:03<00:00, 2789.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESS the original data, SPLIT into train and val data, ENCODE train data, get the DATALOADER \n",
    "processed_data = preprocess_data(data)\n",
    "# if not taking external data for validation \n",
    "if not EXT_VAL_DATA:\n",
    "    X_train, X_val, y_train, y_val = split_data(processed_data) \n",
    "\n",
    "# if using external data for validation:\n",
    "if EXT_VAL_DATA:\n",
    "    X_train, y_train = train_data.applymap(str), train_data['gold_label']\n",
    "    X_val, y_val = val_data.applymap(str), val_data['gold_label']\n",
    "\n",
    "# X_train, X_val, y_train, y_val = X_train[:BATCH_SIZE], X_val[:BATCH_SIZE], y_train[:BATCH_SIZE], y_val[:BATCH_SIZE] \n",
    "# X_train, X_val, y_train, y_val = X_train[:100*BATCH_SIZE], X_val[:100*BATCH_SIZE], y_train[:100*BATCH_SIZE], y_val[:100*BATCH_SIZE] \n",
    "\n",
    "train_input = encode_data(X_train, y_train, xlmr_tokenizer)\n",
    "val_input = encode_data(X_val, y_val, xlmr_tokenizer)\n",
    "NUM_TRAIN_SAMPLES = len(train_input)\n",
    "NUM_VAL_SAMPLES = len(val_input)\n",
    "\n",
    "train_dataloader = create_dataloader(train_input)\n",
    "val_dataloader = create_dataloader(val_input)\n",
    "NUM_TRAIN_BATCHES = len(train_dataloader)\n",
    "NUM_VAL_BATCHES = len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# How to choose the MAX_LEN hyperparameter:\\n# choose a multiple of 2 close to the max length of the input:\\ndef get_max_len(dataset):\\n    max_len = 0\\n    for sample in dataset:\\n        curr_len = sample['tokenized_text'].shape[1]\\n        if curr_len > max_len:\\n            max_len = curr_len \\n    return max_len \\n\\nmax_len_train = get_max_len(train_input) \\nmax_len_val = get_max_len(val_input)\\n\\nprint(max_len_train, max_len_val)\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore\n",
    "'''\n",
    "# How to choose the MAX_LEN hyperparameter:\n",
    "# choose a multiple of 2 close to the max length of the input:\n",
    "def get_max_len(dataset):\n",
    "    max_len = 0\n",
    "    for sample in dataset:\n",
    "        curr_len = sample['tokenized_text'].shape[1]\n",
    "        if curr_len > max_len:\n",
    "            max_len = curr_len \n",
    "    return max_len \n",
    "\n",
    "max_len_train = get_max_len(train_input) \n",
    "max_len_val = get_max_len(val_input)\n",
    "\n",
    "print(max_len_train, max_len_val)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class:\n",
    "class xlmr_model(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(xlmr_model, self).__init__() \n",
    "        self.config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "        self.model = AutoModel.from_pretrained(MODEL_NAME, num_labels=n_classes).to(DEVICE)\n",
    "        self.drop = nn.Dropout(p=DROP_PROB) \n",
    "        classifier_input_dim = self.model.config.hidden_size\n",
    "        self.classifier = nn.Linear(classifier_input_dim, n_classes) \n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.model(\n",
    "                             input_ids = input_ids, \n",
    "                             attention_mask = attention_mask,\n",
    "                             token_type_ids = token_type_ids\n",
    "                             # labels = labels # deprecated\n",
    "                             )\n",
    "        last_hidden_state = outputs[0]  # outputs.last_hidden_state\n",
    "        sentence_embeddings = torch.mean(last_hidden_state, dim=1) \n",
    "        \n",
    "        pooler_output = outputs[1] # outputs.pooler_output\n",
    "        \n",
    "        # output = self.drop(pooler_output) \n",
    "        # pooler output gives processed cls tokens, it might not be the suitable option for nli; will see later\n",
    "        output = self.drop(sentence_embeddings)\n",
    "        # output = sentence_embeddings # when removing dropout, uncomment this line\n",
    "        logits = self.classifier(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = xlmr_model(NUM_CLASSES).to(DEVICE) # the.to(DEVICE) used here might be redundant\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR, correct_bias=False)\n",
    "\n",
    "total_steps = len(train_dataloader) * NUM_EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "                                            optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=total_steps\n",
    "                                            )\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE) \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard (with PyTorch) tutorials:\n",
    "- https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html   \n",
    "- https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# writer = SummaryWriter(\n",
    "#                        \"runs/XLM-R for multilingual NLI\", \n",
    "#                        comment=f\"Learning Rate: {LR} with linear scheduler, Dropout Probability: {DROP_PROB}\"\n",
    "#                        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tensorboard stuff:\n",
    "# %load_ext tensorboard # Load the TensorBoard notebook extension \n",
    "# !rm -rf ./logs/  # Clear any logs from previous runs\n",
    "\n",
    "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "# tensorboard_callack = tf.keras.callbacks.TesnorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a single epoch:\n",
    "def train_epoch(model, dataloader):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0 \n",
    "    correct_preds = 0 \n",
    "    num_samples = 0 \n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    for batch_idx, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "    # for batch_idx, batch in enumerate(dataloader):\n",
    "        ip_ids = batch['tokenized_text'].to(DEVICE)\n",
    "        attn_mask = batch['attention_mask'].to(DEVICE)\n",
    "        token_types = batch['token_types'].to(DEVICE)\n",
    "        targets = batch['outputs'].to(DEVICE).view(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        preds = model(input_ids=ip_ids, attention_mask=attn_mask, token_type_ids=token_types)\n",
    "        _, pred_labels = torch.max(preds, dim=1)\n",
    "        correct_preds += torch.sum(pred_labels==targets)\n",
    "        \n",
    "        # The RHS gives #correct predictions for the 'b-th' batch after training on the previous (b-1) batches \n",
    "        # this value should improve as the model sees more batches\n",
    "        # this 'correct' can differ from the 'correct' in case of 'accuracy(model, dataloader)' \n",
    "        # print(preds)\n",
    "        # print()\n",
    "        # print(targets)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        train_loss += loss.item() \n",
    "        # first we evaluate then backpropagate\n",
    "        loss.backward() \n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step() \n",
    "        scheduler.step() \n",
    "        \n",
    "        # num_samples += len(batch) # WRONG! # len(batch) will give the length of the batch dictionary which is 4\n",
    "        num_samples += len(batch['outputs'])\n",
    "\n",
    "        pred_batch, gold_batch = list(pred_labels.cpu().numpy()), list(targets.cpu().numpy()) \n",
    "        all_preds += pred_batch\n",
    "        all_targets += gold_batch\n",
    "    \n",
    "    acc_this_epoch = correct_preds/num_samples\n",
    "    # acc_this_epoch_ = eval_model(model, dataloader) # this can be different from acc_this_epoch\n",
    "    loss_this_epoch = train_loss/num_batches\n",
    "    \n",
    "    micro_f1 = f1_score(all_targets, all_preds, average='micro')\n",
    "    macro_f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "    return acc_this_epoch, train_loss, micro_f1, macro_f1\n",
    "\n",
    "\n",
    "def eval_epoch(model, dataloader):\n",
    "    model.eval() \n",
    "    \n",
    "    val_loss = 0.0 \n",
    "    correct_preds = 0 \n",
    "    num_samples = 0 \n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        # for batch_idx, batch in enumerate(dataloader):\n",
    "            ip_ids = batch['tokenized_text'].to(DEVICE)\n",
    "            attn_mask = batch['attention_mask'].to(DEVICE)\n",
    "            token_types = batch['token_types'].to(DEVICE)\n",
    "            targets = batch['outputs'].to(DEVICE).view(-1)\n",
    "            \n",
    "            preds = model(input_ids=ip_ids, attention_mask=attn_mask, token_type_ids=token_types) \n",
    "            _, pred_labels = torch.max(preds, dim=1)\n",
    "            correct_preds += torch.sum(pred_labels==targets)\n",
    "\n",
    "            loss = loss_fn(preds, targets) \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            num_samples += len(batch['outputs'])\n",
    "\n",
    "            pred_batch, gold_batch = list(pred_labels.cpu().numpy()), list(targets.cpu().numpy()) \n",
    "            all_preds += pred_batch\n",
    "            all_targets += gold_batch\n",
    "                \n",
    "    acc_this_epoch = correct_preds/num_samples \n",
    "    loss_this_epoch = val_loss/num_batches \n",
    "    \n",
    "    micro_f1 = f1_score(all_targets, all_preds, average='micro')\n",
    "    macro_f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "    return acc_this_epoch, loss_this_epoch, micro_f1, macro_f1\n",
    "\n",
    "\n",
    "def save_model(model, idx):\n",
    "    torch.save(model.state_dict(), f'model_{idx}.pth')\n",
    "    return\n",
    "\n",
    "def load_model(model_path):\n",
    "    state_dict = torch.load(model_path)\n",
    "    model = xlmr_model(NUM_CLASSES)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "def save_history(history_dict):\n",
    "    pickle_on = open('history_dict.pkl', 'wb')\n",
    "    pickle.dump(history_dict, pickle_on)\n",
    "    pickle_on.close()\n",
    "    return\n",
    "\n",
    "def load_history(history_dict_path):\n",
    "    pickle_off = open(history_dict_path, 'rb')\n",
    "    history = pickle.load(pickle_off)\n",
    "    return history\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs):\n",
    "    history = defaultdict(list)\n",
    "    best_acc = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Program execution start : {datetime.datetime.now()}\")\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        print(\"-\"*100)\n",
    "        print(f\"Epoch {int(epoch_idx)}\")\n",
    "        \n",
    "        train_acc, train_loss, train_micro_f1, train_macro_f1 = train_epoch(model, train_loader)\n",
    "        # writer.add_scalar(\"Loss/train\", train_loss, epoch_idx+1)\n",
    "        # writer.add_scalar(\"Accuracy/train\", train_acc, epoch_idx+1)\n",
    "        print(\"Train Acc: {:6.3f} | Micro-F1: {:6.3f} | Macro-F1: {:6.3f} | Train Loss: {:6.3f}\".format(train_acc, train_micro_f1, train_macro_f1, train_loss))\n",
    "        \n",
    "        val_acc, val_loss, val_micro_f1, val_macro_f1 = eval_epoch(model, val_loader)\n",
    "        # writer.add_scalar(\"Loss/test\", val_loss, epoch_idx+1)\n",
    "        # writer.add_scalar(\"Accuracy/test\", val_acc, epoch_idx+1)\n",
    "        print(\"Val Acc: {:6.3f} | Micro-F1: {:6.3f} | Macro-F1: {:6.3f} | Val Loss: {:6.3f}\".format(val_acc, val_micro_f1, val_macro_f1, val_loss))\n",
    "        \n",
    "        print(\"-\"*100)\n",
    "\n",
    "        history['train_accs'].append(train_acc.cpu().item()) # micro-F1\n",
    "        history['train_losses'].append(train_loss)\n",
    "        history['val_accs'].append(val_acc.cpu().item())\n",
    "        history['val_losses'].append(val_loss)\n",
    "        \n",
    "        history['train_micro-f1'].append(train_micro_f1)\n",
    "        history['train_macro-f1'].append(train_macro_f1)\n",
    "        history['val_macro-f1'].append(val_micro_f1)\n",
    "        history['val_macro-f1'].append(val_macro_f1)\n",
    "        # saving the model at every checkpoint might take too much space but we don't care xD\n",
    "        # we save the model at every epoch (each checkpoint's size is around 1.1 GB)\n",
    "        # we also save the entire 'history' \n",
    "        # we'll select the one of the model checkpoints later based on the history \n",
    "        save_model(model, epoch_idx)\n",
    "    \n",
    "    save_history(history) \n",
    "    print(f\"Program execution end : {datetime.datetime.now()}\")\n",
    "    print()\n",
    "    end_time = time.time() \n",
    "    print(f\"Total execution time: {(end_time-start_time)/3600} hrs\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. What should be the MAX_LEN?    \n",
    "Q. Give the concatenated {premise, hypothesis} as single input or consider separate inputs premise and hypothesis (in the latter case there will be separate segment embeddings for the two inputs which will necessiate the use of token_type_ids input for the model) i.e., \n",
    "- use Tokenizer(text=proposition, ...)\n",
    "- use Tokenizer(text=premise, text_pair=hypothesis, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program execution start : 2022-11-26 14:22:26.224259\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3532/3532 [43:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:  0.815 | Train Loss: 1658.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 312/312 [01:08<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:  0.849 | Val Loss:  0.464\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3532/3532 [43:08<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:  0.886 | Train Loss: 1107.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 312/312 [01:08<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:  0.865 | Val Loss:  0.562\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3532/3532 [43:07<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:  0.914 | Train Loss: 870.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 312/312 [01:08<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:  0.876 | Val Loss:  0.655\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3532/3532 [43:08<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:  0.934 | Train Loss: 702.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 312/312 [01:08<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:  0.873 | Val Loss:  0.721\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3532/3532 [43:08<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:  0.949 | Train Loss: 568.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 312/312 [01:08<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:  0.876 | Val Loss:  0.797\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3532/3532 [43:08<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:  0.960 | Train Loss: 491.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 312/312 [01:08<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:  0.878 | Val Loss:  0.835\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3532/3532 [43:09<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:  0.967 | Train Loss: 427.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 312/312 [01:08<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:  0.880 | Val Loss:  0.820\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3532/3532 [43:09<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:  0.973 | Train Loss: 366.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 312/312 [01:08<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:  0.878 | Val Loss:  0.888\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3532/3532 [43:08<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:  0.977 | Train Loss: 331.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 312/312 [01:08<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:  0.876 | Val Loss:  0.891\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3532/3532 [43:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc:  0.979 | Train Loss: 310.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 312/312 [01:08<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc:  0.874 | Val Loss:  0.855\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Program execution end : 2022-11-26 21:45:56.576751\n",
      "\n",
      "Total execution time: 7.391764610542191 hrs\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=runs\n",
    "\n",
    "# writer.flush() \n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'train_accs': [0.8148115277290344, 0.8857274055480957, 0.9137203097343445, 0.9335445165634155, 0.9488729238510132, 0.9597674012184143, 0.9667412638664246, 0.973024845123291, 0.976892352104187, 0.9790252447128296], 'train_losses': [1658.941638402408, 1107.2093811953964, 870.1207627179974, 702.7540937981685, 568.4107035556808, 491.96895518913334, 427.7654407773771, 366.94175416487815, 331.4733188902792, 310.466303849229], 'val_accs': [0.8485943675041199, 0.8653614521026611, 0.8758032321929932, 0.8734939694404602, 0.8761044144630432, 0.8779116868972778, 0.8803213238716125, 0.8784136772155762, 0.8756024241447449, 0.873795211315155], 'val_losses': [0.4644244694455455, 0.5619034880353586, 0.6551157749402662, 0.7212011052497473, 0.7967371219077648, 0.8349079333425391, 0.8204258104133376, 0.8876115394754939, 0.890777366499081, 0.8545642026486185]})\n"
     ]
    }
   ],
   "source": [
    "hist = load_history('history_dict.pkl')\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
